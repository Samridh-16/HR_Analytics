{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33c4c052-f71d-434d-a014-87c64a3f1b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (1470, 35)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1470 entries, 0 to 1469\n",
      "Data columns (total 35 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Age                       1470 non-null   int64 \n",
      " 1   Attrition                 1470 non-null   object\n",
      " 2   BusinessTravel            1470 non-null   object\n",
      " 3   DailyRate                 1470 non-null   int64 \n",
      " 4   Department                1470 non-null   object\n",
      " 5   DistanceFromHome          1470 non-null   int64 \n",
      " 6   Education                 1470 non-null   int64 \n",
      " 7   EducationField            1470 non-null   object\n",
      " 8   EmployeeCount             1470 non-null   int64 \n",
      " 9   EmployeeNumber            1470 non-null   int64 \n",
      " 10  EnvironmentSatisfaction   1470 non-null   int64 \n",
      " 11  Gender                    1470 non-null   object\n",
      " 12  HourlyRate                1470 non-null   int64 \n",
      " 13  JobInvolvement            1470 non-null   int64 \n",
      " 14  JobLevel                  1470 non-null   int64 \n",
      " 15  JobRole                   1470 non-null   object\n",
      " 16  JobSatisfaction           1470 non-null   int64 \n",
      " 17  MaritalStatus             1470 non-null   object\n",
      " 18  MonthlyIncome             1470 non-null   int64 \n",
      " 19  MonthlyRate               1470 non-null   int64 \n",
      " 20  NumCompaniesWorked        1470 non-null   int64 \n",
      " 21  Over18                    1470 non-null   object\n",
      " 22  OverTime                  1470 non-null   object\n",
      " 23  PercentSalaryHike         1470 non-null   int64 \n",
      " 24  PerformanceRating         1470 non-null   int64 \n",
      " 25  RelationshipSatisfaction  1470 non-null   int64 \n",
      " 26  StandardHours             1470 non-null   int64 \n",
      " 27  StockOptionLevel          1470 non-null   int64 \n",
      " 28  TotalWorkingYears         1470 non-null   int64 \n",
      " 29  TrainingTimesLastYear     1470 non-null   int64 \n",
      " 30  WorkLifeBalance           1470 non-null   int64 \n",
      " 31  YearsAtCompany            1470 non-null   int64 \n",
      " 32  YearsInCurrentRole        1470 non-null   int64 \n",
      " 33  YearsSinceLastPromotion   1470 non-null   int64 \n",
      " 34  YearsWithCurrManager      1470 non-null   int64 \n",
      "dtypes: int64(26), object(9)\n",
      "memory usage: 402.1+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = r\"C:\\Users\\SKY\\Desktop\\JOB prep\\Repostiores folders\\Project-3 HR Analytics\\DATA\\WA_Fn-UseC_-HR-Employee-Attrition.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53620b1e-4c56-4947-b493-4bbdbfb94840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null/Missing values per column:\n",
      "Series([], dtype: int64)\n",
      "No missing values found in the dataset\n",
      "\n",
      "Total missing values: 0\n",
      "Percentage of missing data: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Checking For Empty Cells\n",
    "null_counts = df.isnull().sum()\n",
    "print(\"Null/Missing values per column:\")\n",
    "print(null_counts[null_counts > 0])\n",
    "\n",
    "if null_counts.sum() == 0:\n",
    "    print(\"No missing values found in the dataset\")\n",
    "\n",
    "print(f\"\\nTotal missing values: {null_counts.sum()}\")\n",
    "print(f\"Percentage of missing data: {(null_counts.sum() / (df.shape[0] * df.shape[1])) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a259d7a2-ae8d-4742-8c30-cc2859e2fc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No empty strings found\n"
     ]
    }
   ],
   "source": [
    "# Checking For Empty Strings\n",
    "empty_strings = pd.DataFrame()\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    empty_count = (df[col] == '').sum()\n",
    "    if empty_count > 0:\n",
    "        empty_strings[col] = [empty_count]\n",
    "if len(empty_strings) > 0:\n",
    "    print(\"Empty strings found:\")\n",
    "    print(empty_strings)\n",
    "else:\n",
    "    print(\"No empty strings found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4525c41c-cdf0-46a7-bb08-829e2e010ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n",
      "Duplicate employee numbers: 0\n"
     ]
    }
   ],
   "source": [
    "# CHECKING FOR DUPLICATES\n",
    "duplicate_rows = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicate_rows}\")\n",
    "if duplicate_rows > 0:\n",
    "    print(\"Duplicate rows found:\")\n",
    "    print(df[df.duplicated()])\n",
    "duplicate_employees = df['EmployeeNumber'].duplicated().sum()\n",
    "print(f\"Duplicate employee numbers: {duplicate_employees}\")\n",
    "if duplicate_employees > 0:\n",
    "    print(\"Duplicate employee numbers found:\")\n",
    "    print(df[df['EmployeeNumber'].duplicated(keep=False)].sort_values('EmployeeNumber'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60062a83-5b1c-480e-a5f9-81b31123f17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attrition: 2 unique values\n",
      "Values: ['Yes', 'No']\n",
      "Distribution: {'No': np.int64(1233), 'Yes': np.int64(237)}\n",
      "\n",
      "BusinessTravel: 3 unique values\n",
      "Values: ['Travel_Rarely', 'Travel_Frequently', 'Non-Travel']\n",
      "\n",
      "Department: 3 unique values\n",
      "Values: ['Sales', 'Research & Development', 'Human Resources']\n",
      "\n",
      "EducationField: 6 unique values\n",
      "Values: ['Life Sciences', 'Other', 'Medical', 'Marketing', 'Technical Degree', 'Human Resources']\n",
      "\n",
      "Gender: 2 unique values\n",
      "Values: ['Female', 'Male']\n",
      "Distribution: {'Male': np.int64(882), 'Female': np.int64(588)}\n",
      "\n",
      "JobRole: 9 unique values\n",
      "Values: ['Sales Executive', 'Research Scientist', 'Laboratory Technician', 'Manufacturing Director', 'Healthcare Representative', 'Manager', 'Sales Representative', 'Research Director', 'Human Resources']\n",
      "\n",
      "MaritalStatus: 3 unique values\n",
      "Values: ['Single', 'Married', 'Divorced']\n",
      "\n",
      "Over18: 1 unique values\n",
      "Values: ['Y']\n",
      "Distribution: {'Y': np.int64(1470)}\n",
      "\n",
      "OverTime: 2 unique values\n",
      "Values: ['Yes', 'No']\n",
      "Distribution: {'No': np.int64(1054), 'Yes': np.int64(416)}\n"
     ]
    }
   ],
   "source": [
    "# CHECKING CATEGORICAL DATA CONSISTENCY\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    unique_values = df[col].unique()\n",
    "    print(f\"\\n{col}: {len(unique_values)} unique values\")\n",
    "    print(f\"Values: {list(unique_values)}\")\n",
    "    if col in ['Attrition', 'Gender', 'Over18', 'OverTime']:\n",
    "        value_counts = df[col].value_counts()\n",
    "        print(f\"Distribution: {dict(value_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78a96230-dcaa-43ba-88ce-65cb6477df77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmployeeCount: constant value = 1\n",
      "Over18: constant value = Y\n",
      "StandardHours: constant value = 80\n"
     ]
    }
   ],
   "source": [
    "# CHECKING FOR CONSTANT COLUMNS\n",
    "constant_cols = []\n",
    "for col in df.columns:\n",
    "    if df[col].nunique() == 1:\n",
    "        constant_cols.append(col)\n",
    "        print(f\"{col}: constant value = {df[col].iloc[0]}\")\n",
    "if not constant_cols:\n",
    "    print(\"No constant columns found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c782529-9689-4542-9488-24bdecfbee7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved successfully at: C:\\Users\\SKY\\Desktop\\JOB prep\\Repostiores folders\\Project-3 HR Analytics\\DATA\\WA_Fn-UseC_-HR-Employee-Attrition_checked.csv\n",
      "Dataset shape: (1470, 35)\n",
      "Memory usage: 1,065,501 bytes\n"
     ]
    }
   ],
   "source": [
    "# SAVING DATASET\n",
    "output_path = r\"C:\\Users\\SKY\\Desktop\\JOB prep\\Repostiores folders\\Project-3 HR Analytics\\DATA\\WA_Fn-UseC_-HR-Employee-Attrition_checked.csv\"\n",
    "\n",
    "try:\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Dataset saved successfully at: {output_path}\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum():,} bytes\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving file: {str(e)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
